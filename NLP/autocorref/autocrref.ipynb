{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04193f2",
   "metadata": {},
   "source": [
    "# Natural language processing (NLP) and probabilistic models\n",
    "\n",
    "## Word-Processing Autocorref Algorithn compilation \n",
    "\n",
    "We use the autocorrect functionality everyday on our laptops, cell phones, computers etc. \n",
    "\n",
    "In this notebook, I aim to create a basic auto-correct tool and explore what goes on behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a228ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import textdistance # lib designed ofr computing distance between words (strings)\n",
    "# from nltk.corpus import words # English dictionary\n",
    "\n",
    "from nltk.corpus import brown # Brown dictionary\n",
    "\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b763be",
   "metadata": {},
   "source": [
    "# Part A - WORDS\n",
    "\n",
    "### Step 1:\n",
    "\n",
    "1. Read the corpus (txt) file -> Download the corpus dictionary: Brown Dicionary\n",
    "2. Change everything to lowercase\n",
    "3. Return a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da3dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "399\n",
      "445\n"
     ]
    }
   ],
   "source": [
    "# Download the Brown corpus if not already\n",
    "# nltk.download(\"brown\")\n",
    "\n",
    "# Load Bown nglish words and create frequency dictionary - TOKENIZATION\n",
    "vocab = brown.words()\n",
    "\n",
    "# Create a frequency dictionary from the Brown corpus -  how many times each word appears in the Brown corpus.\n",
    "vocab = Counter([w.lower() for w in vocab]) \n",
    "\n",
    "# Remove words that are not alphabetic or contain non-ASCII characters\n",
    "# vocab = {word: freq for word, freq in vocab.items() if word.isalpha() and all(ord(c) < 128 for c in word)}\n",
    "\n",
    "## Verify if words are on the dictionary (brown)\n",
    "print(vocab['goin'])   # Should be > 0\n",
    "print(vocab['going'])  # Should be much higher\n",
    "print(vocab[\"water\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb0c19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c428a0",
   "metadata": {},
   "source": [
    "Interprettion:\n",
    "\n",
    " \"goin\" is a real token in the Brown corpus — but it's informal/colloquial. \n",
    " Since it exists, the code treats it as valid and doesn’t correct it.\n",
    "\n",
    "### Autocorrect functions -  Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b94ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction function V1 - Levenshtein distance\n",
    "def get_closest_word(input_word, vocab=vocab, max_dist=2):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    if input_word in vocab:\n",
    "        return input_word\n",
    "    \n",
    "    # Generate possible corrections\n",
    "    candidates = [word for word in vocab if textdistance.levenshtein(input_word, word) <= max_dist]\n",
    "    \n",
    "    if not candidates:\n",
    "        return input_word  # No close match found\n",
    "\n",
    "    # Return the most frequent close match\n",
    "    return max(candidates, key=lambda w: vocab[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c33d696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goin'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_word(\"goin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30b1f5",
   "metadata": {},
   "source": [
    "So, the code returns goin, as it is a toke, but we need to remove that\n",
    "\n",
    "### V2 - Add a frequency threshold\n",
    "\n",
    "#### Avoid returning low-frequency, informal words like \"goin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55882fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction function V2 - Levenshtein distance - FREQUENCY THRESHOLD\n",
    "\n",
    "def get_closest_word_v2(input_word, vocab=vocab, max_dist=2, min_freq=10):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    # Only return it if it's common enough\n",
    "    if input_word in vocab and vocab[input_word] >= min_freq:\n",
    "        return input_word\n",
    "    \n",
    "    # Generate possible corrections\n",
    "    candidates = [\n",
    "        word for word in vocab \n",
    "        if textdistance.levenshtein(input_word, word) <= max_dist\n",
    "        and vocab[word] >= min_freq  # Filter here too\n",
    "    ]\n",
    "    \n",
    "    if not candidates:\n",
    "        return input_word\n",
    "\n",
    "    return max(candidates, key=lambda w: vocab[w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b4b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_word_v2(\"goin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4537b5a",
   "metadata": {},
   "source": [
    "Intuition: \n",
    "* Function is working, but not giving the most semantically relevant result.\n",
    "* FAUNCTION RETURNS the most (MAX) frequent word among all within max_dist = 2. Since \"in\" is a super common word in English, it's getting selected — even though \"going\" is a better correction for \"goin\".\n",
    "\n",
    "### V3 - Score by distance and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ad70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "def get_closest_word_v3(input_word, vocab=vocab, max_dist=2, min_freq=10):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    # Only return it if it's common enough ( FREQUENCY THRESHOLD)\n",
    "    if input_word in vocab and vocab[input_word] >= min_freq:\n",
    "        return input_word\n",
    "\n",
    "    candidates = []\n",
    "    for word in vocab:\n",
    "        if vocab[word] < min_freq:\n",
    "            continue\n",
    "        dist = textdistance.levenshtein(input_word, word)\n",
    "        if dist <= max_dist:\n",
    "            score = -dist + 0.001 * vocab[word]\n",
    "            candidates.append((word, score))\n",
    "\n",
    "    if not candidates:\n",
    "        return input_word\n",
    "\n",
    "    # Return word with best score\n",
    "    return max(candidates, key=lambda x: x[1])[0]\n",
    "\n",
    "print(get_closest_word_v3(\"goin\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_closest_word_v4(input_word, vocab=vocab, max_dist=2, min_freq=10):\n",
    "    input_word = input_word.lower()\n",
    "    \n",
    "    if input_word in vocab and vocab[input_word] >= min_freq:\n",
    "        return input_word\n",
    "\n",
    "    candidates = []\n",
    "    for word in vocab:\n",
    "        if vocab[word] < min_freq:\n",
    "            continue\n",
    "\n",
    "        dist = textdistance.levenshtein(input_word, word)\n",
    "\n",
    "        if dist <= max_dist:\n",
    "            # Penalize shorter words and large length differences\n",
    "            len_diff_penalty = abs(len(input_word) - len(word)) * 0.5\n",
    "            score = -dist - len_diff_penalty + 0.001 * vocab[word]\n",
    "            candidates.append((word, score))\n",
    "\n",
    "    if not candidates:\n",
    "        return input_word\n",
    "\n",
    "    return max(candidates, key=lambda x: x[1])[0]\n",
    "print(get_closest_word_v4(\"goin\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eff147",
   "metadata": {},
   "source": [
    "Now, you understood how difficult it is to build a good autocrref algorithn \n",
    "\n",
    "Let's build more complex score values:\n",
    "\n",
    "* Adding a prefix constraint - first letter must have\n",
    "* Penalizing edit distance (good)\n",
    "* Boosting frequency using sqrt(freq) (smooths out the effect of very high-frequency words like \"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911612d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggestions for 'goin':\n",
      "1. going           (distance=1, freq=399, score=9.48)\n",
      "2. good            (distance=2, freq=806, score=9.03)\n",
      "3. go              (distance=2, freq=626, score=7.01)\n",
      "4. got             (distance=2, freq=482, score=5.17)\n",
      "5. goin            (distance=0, freq=4, score=2.70)\n",
      "\n",
      "Suggestions for 'stp':\n",
      "1. she             (distance=2, freq=2860, score=24.09)\n",
      "2. so              (distance=2, freq=1985, score=18.73)\n",
      "3. see             (distance=2, freq=772, score=8.67)\n",
      "4. say             (distance=2, freq=504, score=5.47)\n",
      "5. set             (distance=2, freq=414, score=4.21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('she', 2, 2860),\n",
       " ('so', 2, 1985),\n",
       " ('see', 2, 772),\n",
       " ('say', 2, 504),\n",
       " ('set', 2, 414)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_candidates_v5(word, vocab=vocab, max_dist=2, top_n=5):\n",
    "    word = word.lower()\n",
    "    candidates = []\n",
    "\n",
    "    for w in vocab:\n",
    "        if w[0] != word[0]:  # Must match first letter\n",
    "            continue\n",
    "\n",
    "        dist = textdistance.levenshtein(word, w)\n",
    "        if dist <= max_dist:\n",
    "            freq = vocab[w]\n",
    "            prefix_bonus = 1.5 if w.startswith(word[:3]) else 0\n",
    "            score = -4 * dist + 0.6 * (freq ** 0.5) + prefix_bonus\n",
    "            candidates.append((w, dist, freq, score))\n",
    "\n",
    "    sorted_candidates = sorted(candidates, key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    print(f\"\\nSuggestions for '{word}':\")\n",
    "    for i, (w, d, f, s) in enumerate(sorted_candidates[:top_n], start=1):\n",
    "        print(f\"{i}. {w:<15} (distance={d}, freq={f}, score={s:.2f})\")\n",
    "\n",
    "    return [(w, d, f) for w, d, f, _ in sorted_candidates[:top_n]]\n",
    "\n",
    "get_candidates_v5(\"goin\")\n",
    "\n",
    "get_candidates_v5(\"stp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b843057",
   "metadata": {},
   "source": [
    "### Does the logic works for other words like stop -  \"stp\"? \n",
    "\n",
    "It depends!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df0be934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Suggestions for 'stp':\n",
      "1. she             (distance=2, freq=2860, score=24.09)\n",
      "2. so              (distance=2, freq=1985, score=18.73)\n",
      "3. see             (distance=2, freq=772, score=8.67)\n",
      "4. say             (distance=2, freq=504, score=5.47)\n",
      "5. set             (distance=2, freq=414, score=4.21)\n",
      "\n",
      "Suggestions for 'maximn':\n",
      "1. maximum         (distance=2, freq=79, score=-1.17)\n",
      "2. main            (distance=2, freq=119, score=-1.45)\n",
      "3. maxim           (distance=1, freq=1, score=-1.90)\n",
      "4. maximal         (distance=2, freq=3, score=-5.46)\n",
      "5. maxine          (distance=2, freq=2, score=-5.65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('maximum', 2, 79),\n",
       " ('main', 2, 119),\n",
       " ('maxim', 1, 1),\n",
       " ('maximal', 2, 3),\n",
       " ('maxine', 2, 2)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Does the logic works for other words like stop -  \"stp\"?\n",
    "get_candidates_v5(\"stp\")\n",
    "get_candidates_v5(\"maximn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005e946",
   "metadata": {},
   "source": [
    "# Part B: Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb02dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textdistance\n",
    "from math import sqrt\n",
    "\n",
    "VOWELS = set(\"aeiou\")\n",
    "\n",
    "def consonant_skeleton(w: str) -> str:\n",
    "    w = w.lower()\n",
    "    return \"\".join(ch for ch in w if ch.isalpha() and ch not in VOWELS)\n",
    "\n",
    "def is_subsequence(small: str, large: str) -> bool:\n",
    "    \"\"\"Return True if all chars in `small` appear in order inside `large`.\"\"\"\n",
    "    it = iter(large)\n",
    "    return all(c in it for c in small)\n",
    "\n",
    "def score_candidate(candidate: str, original: str, dist: int, freq: int) -> float:\n",
    "    # Base: strong penalty for distance, soft bonus for frequency\n",
    "    score = -2.5 * dist + 0.1 * sqrt(freq)\n",
    "\n",
    "    # Heuristic bonuses\n",
    "    if consonant_skeleton(candidate) == consonant_skeleton(original):\n",
    "        score += 12  # same consonant pattern (often missing vowel)\n",
    "    if is_subsequence(original, candidate):\n",
    "        score += 6   # original is a subsequence of candidate\n",
    "    # Small prefix bonus\n",
    "    if candidate.startswith(original[:2]):\n",
    "        score += 2\n",
    "\n",
    "    # Penalize very rare exact matches (e.g., slang/typos captured in corpus)\n",
    "    if dist == 0 and freq < 10:\n",
    "        score -= 4\n",
    "\n",
    "    return score\n",
    "\n",
    "def get_candidates_v2(word, max_dist=2, top_n=5):\n",
    "    word = word.lower()\n",
    "    candidates = []\n",
    "\n",
    "    for w in vocab:  # vocab is your Counter from brown\n",
    "        dist = textdistance.levenshtein(word, w)\n",
    "        if dist <= max_dist:\n",
    "            freq = vocab[w]\n",
    "            s = score_candidate(w, word, dist, freq)\n",
    "            candidates.append((w, dist, freq, s))\n",
    "\n",
    "    candidates.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    # Debug print\n",
    "    print(f\"\\nSuggestions for '{word}':\")\n",
    "    for i, (w, d, f, s) in enumerate(candidates[:top_n], start=1):\n",
    "        print(f\"{i}. {w} (distance={d}, freq={f}, score={s:.2f})\")\n",
    "\n",
    "    return [(w, d, f) for w, d, f, _ in candidates[:top_n]]\n",
    "\n",
    "def clean_slang(word):\n",
    "    \"\"\"Fix known informal/slang before correction.\"\"\"\n",
    "    rules = {\n",
    "        \"goin\": \"going\",\n",
    "        \"comin\": \"coming\",\n",
    "        \"doin\": \"doing\",\n",
    "        \"runnin\": \"running\",\n",
    "        \"tryin\": \"trying\",\n",
    "        \"wanna\": \"want to\",\n",
    "        \"gonna\": \"going to\"\n",
    "    }\n",
    "    return rules.get(word.lower(), word)\n",
    "\n",
    "def correct_word(word, max_dist=2):\n",
    "    word = clean_slang(word)\n",
    "    suggestions = get_candidates_v2(word, max_dist=max_dist, top_n=1)\n",
    "    return suggestions[0][0] if suggestions else word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b15d818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "print(\"going\" in vocab)  \n",
    "print(textdistance.levenshtein(\"goin\", \"going\"))  # should return 2\n",
    "print(vocab[\"going\"])  # should return its frequency (you said ~399)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c3e8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I am goin to teh store\n",
      "['I', ' ', 'am', ' ', 'goin', ' ', 'to', ' ', 'teh', ' ', 'store']\n",
      "Suggestions for 'I':\n",
      "\n",
      "Suggestions for 'i':\n",
      "1. , (distance=1, freq=58334, score=33.65)\n",
      "Suggestions for 'am':\n",
      "\n",
      "Suggestions for 'am':\n",
      "1. am (distance=0, freq=237, score=21.54)\n",
      "Suggestions for 'goin':\n",
      "\n",
      "Suggestions for 'going':\n",
      "1. going (distance=0, freq=399, score=22.00)\n",
      "Suggestions for 'to':\n",
      "\n",
      "Suggestions for 'to':\n",
      "1. to (distance=0, freq=26158, score=36.17)\n",
      "Suggestions for 'teh':\n",
      "\n",
      "Suggestions for 'teh':\n",
      "1. the (distance=2, freq=69971, score=33.45)\n",
      "Suggestions for 'store':\n",
      "\n",
      "Suggestions for 'store':\n",
      "1. store (distance=0, freq=74, score=20.86)\n",
      "Corrected: , am going to the store\n",
      "----------------------------------------\n",
      "Original: Lets strt builidng autocrrect\n",
      "['Lets', ' ', 'strt', ' ', 'builidng', ' ', 'autocrrect']\n",
      "Suggestions for 'Lets':\n",
      "\n",
      "Suggestions for 'lets':\n",
      "1. let's (distance=1, freq=69, score=18.33)\n",
      "Suggestions for 'strt':\n",
      "\n",
      "Suggestions for 'strt':\n",
      "1. start (distance=1, freq=154, score=18.74)\n",
      "Suggestions for 'builidng':\n",
      "\n",
      "Suggestions for 'builidng':\n",
      "1. building (distance=2, freq=160, score=10.26)\n",
      "Suggestions for 'autocrrect':\n",
      "\n",
      "Suggestions for 'autocrrect':\n",
      "Corrected: let's start building autocrrect\n",
      "----------------------------------------\n",
      "Original: Recieve and adress should be corrected\n",
      "['Recieve', ' ', 'and', ' ', 'adress', ' ', 'should', ' ', 'be', ' ', 'corrected']\n",
      "Suggestions for 'Recieve':\n",
      "\n",
      "Suggestions for 'recieve':\n",
      "1. receive (distance=2, freq=76, score=9.87)\n",
      "Suggestions for 'and':\n",
      "\n",
      "Suggestions for 'and':\n",
      "1. and (distance=0, freq=28853, score=36.99)\n",
      "Suggestions for 'adress':\n",
      "\n",
      "Suggestions for 'adress':\n",
      "1. dress (distance=1, freq=67, score=10.32)\n",
      "Suggestions for 'should':\n",
      "\n",
      "Suggestions for 'should':\n",
      "1. should (distance=0, freq=888, score=22.98)\n",
      "Suggestions for 'be':\n",
      "\n",
      "Suggestions for 'be':\n",
      "1. be (distance=0, freq=6377, score=27.99)\n",
      "Suggestions for 'corrected':\n",
      "\n",
      "Suggestions for 'corrected':\n",
      "1. corrected (distance=0, freq=9, score=16.30)\n",
      "Corrected: receive and dress should be corrected\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "examples = [\n",
    "    \"I am goin to teh store\",\n",
    "    \"Lets strt builidng autocrrect\",\n",
    "    \"Recieve and adress should be corrected\",\n",
    "]\n",
    "\n",
    "for sentences in examples:\n",
    "    print(\"Original:\", sentences)\n",
    "    print(\"Corrected:\", correct_sentence_v2(sentences))\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81bb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autocorrect-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
